{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Experiments using Stochastic Block Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "from torch_geometric.data import DataLoader\n",
    "from itertools import combinations\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from src.utils.CreateFeatures import CreateFeatures\n",
    "from src.pygcn.GCN_synthetic import SiameseGNN\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch_geometric.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_synthetic_pairs(data, cp_time):\n",
    "    all_loader = DataLoader(data, batch_size=32)\n",
    "\n",
    "    all_pairs = list(combinations(range(200), 2))\n",
    "    random_pairs = random.sample(all_pairs, 1000)\n",
    "\n",
    "    graph_pairs = []\n",
    "    for i in random_pairs:\n",
    "        first, second = i[0], i[1]\n",
    "\n",
    "        if first < cp_time and second < cp_time:\n",
    "            y_label = 1\n",
    "        elif first >= cp_time and second >= cp_time:\n",
    "            y_label = 1\n",
    "        else:\n",
    "            y_label = 0\n",
    "\n",
    "        graph_pairs.append((data[first], data[second], y_label))\n",
    "\n",
    "    flattened_train, flattened_test = train_test_split(graph_pairs, test_size=0.40, random_state=42)\n",
    "    flattened_test, flattened_val = train_test_split(graph_pairs, test_size=0.5, random_state=42)\n",
    "\n",
    "    return flattened_train, flattened_test, flattened_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, train_data, val_data):\n",
    "    torch.manual_seed(42)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = StepLR(optimizer, step_size=10, gamma=0.1)  # Adjust step_size and gamma as needed\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    for epoch in tqdm(range(5)):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for data1, data2, label in train_data:\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data1, data2)\n",
    "            label = torch.tensor(label).view(1).float()\n",
    "            loss = criterion(out.squeeze(0), label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        scheduler.step()  # Add this line to update the learning rate\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_losses = []\n",
    "\n",
    "            val_pred = []\n",
    "            val_truth = []\n",
    "\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for data1, data2, label in val_data:\n",
    "                out = model(data1, data2)\n",
    "                label = torch.tensor(label).view(1).float()\n",
    "                val_loss = criterion(out.squeeze(0), label)\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "                predictions = torch.round(out.squeeze())\n",
    "\n",
    "                val_pred.append(predictions)\n",
    "                val_truth.append(label)\n",
    "\n",
    "                correct += (predictions == label).sum().item()\n",
    "                total += 1\n",
    "\n",
    "            val_loss = sum(val_losses) / len(val_losses)\n",
    "            val_accuracy = correct / total\n",
    "\n",
    "        print(f'Epoch: {epoch+1}, Training Loss: {sum(train_losses)/len(train_losses)}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}, Validation F1 Score: {f1_score(val_truth, val_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sinclaireschuetze/Documents/GitHub/Trade-GNN-ChangePoint/.env/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      " 20%|██        | 1/5 [00:30<02:02, 30.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 0.7030626838902633, Validation Loss: 0.6927091188430786, Validation Accuracy: 0.524, Validation F1 Score: 0.6876640419947506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [01:00<01:29, 29.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Training Loss: 0.697512743473053, Validation Loss: 0.6922233791351319, Validation Accuracy: 0.524, Validation F1 Score: 0.6876640419947506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [01:27<00:57, 29.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Training Loss: 0.696107418636481, Validation Loss: 0.6923881580829621, Validation Accuracy: 0.524, Validation F1 Score: 0.6876640419947506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [01:57<00:29, 29.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Training Loss: 0.6961809026201566, Validation Loss: 0.6927824656963348, Validation Accuracy: 0.524, Validation F1 Score: 0.6876640419947506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:26<00:00, 29.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Training Loss: 0.6956245772043864, Validation Loss: 0.6925743868350983, Validation Accuracy: 0.524, Validation F1 Score: 0.6876640419947506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"results/synthetic/06_04_10:47:54_merge_T_200_n_400_k1_4_k2_2_p_0.5_q_0.2_0/data.p\", \"rb\") as f:\n",
    "    merge_data = pkl.load(f)\n",
    "\n",
    "cp_time = 80\n",
    "flattened_train, flattened_test, flattened_val = create_synthetic_pairs(merge_data, cp_time)\n",
    "model = SiameseGNN()\n",
    "run_model(model, flattened_train, flattened_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clique Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sinclaireschuetze/Documents/GitHub/Trade-GNN-ChangePoint/.env/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      " 20%|██        | 1/5 [00:14<00:58, 14.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 0.7027358784526586, Validation Loss: 0.6949385805130005, Validation Accuracy: 0.524, Validation F1 Score: 0.6876640419947506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:28<00:42, 14.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Training Loss: 0.6930854049821694, Validation Loss: 0.6904357953071594, Validation Accuracy: 0.524, Validation F1 Score: 0.6876640419947506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:42<00:28, 14.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Training Loss: 0.6918158697585265, Validation Loss: 0.6914281842708587, Validation Accuracy: 0.524, Validation F1 Score: 0.6876640419947506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:56<00:14, 14.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Training Loss: 0.6835549014310042, Validation Loss: 0.6739447337388992, Validation Accuracy: 0.622, Validation F1 Score: 0.46458923512747874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:11<00:00, 14.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Training Loss: 0.6490362334251404, Validation Loss: 0.6374697284698486, Validation Accuracy: 0.614, Validation F1 Score: 0.4469914040114613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"results/synthetic/06_04_11:13:29_clique_cp_1_T_200_n_400_p_0.2_q_0.05_20_0/data.p\", \"rb\") as f:\n",
    "    clique_data = pkl.load(f)\n",
    "\n",
    "cp_time = 133\n",
    "flattened_train, flattened_test, flattened_val = create_synthetic_pairs(clique_data, cp_time)\n",
    "model = SiameseGNN()\n",
    "run_model(model, flattened_train, flattened_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
